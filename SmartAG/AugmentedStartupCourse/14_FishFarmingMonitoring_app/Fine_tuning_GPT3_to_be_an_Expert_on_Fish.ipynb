{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ac51051-bd7a-4b69-bff0-7370bed71bdd",
      "metadata": {
        "id": "1ac51051-bd7a-4b69-bff0-7370bed71bdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "940735d1-1f84-44ae-a951-2eaba6ffe345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.1.1-py3-none-any.whl (217 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/217.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/217.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m217.8/217.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
            "Collecting httpcore (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.1 httpx-0.25.1 openai-1.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set an environment variable in Colab\n",
        "%env OPENAI_API_KEY=your-api-key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Qmoycb1-WlP",
        "outputId": "4ff8294d-3803-47d1-9e16-32abec376a26"
      },
      "id": "_Qmoycb1-WlP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: OPENAI_API_KEY=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\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "client.files.create(\n",
        "  file=open(\"fish_farming_data.jsonl\", \"rb\"),\n",
        "  purpose=\"fine-tune\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-OYxHMR-Y8y",
        "outputId": "c7a67249-0310-4dd6-aab4-e1ebd18669aa"
      },
      "id": "A-OYxHMR-Y8y",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FileObject(id='file-VLN2wKKZ3ewndFbOgbZ6iWSv', bytes=62406, created_at=1699431926, filename='fish_farming_data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "client.fine_tuning.jobs.create(\n",
        "  training_file=\"file-VLN2wKKZ3ewndFbOgbZ6iWSv\",\n",
        "  model=\"gpt-3.5-turbo\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmaUnOBq-ZkZ",
        "outputId": "396fa5cd-01a8-445c-8f90-d0c70900997b"
      },
      "id": "SmaUnOBq-ZkZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-DopJ3om8YUB0vHmVZokutvKS', created_at=1699440465, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-o0cVjSNF0kV27hbDuF1drh7M', result_files=[], status='validating_files', trained_tokens=None, training_file='file-VLN2wKKZ3ewndFbOgbZ6iWSv', validation_file=None)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "# Retrieve the state of a fine-tune\n",
        "client.fine_tuning.jobs.retrieve(\"ftjob-Y0cAZOKMsTzbPy2B4QX8lPMU\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ga1-p0bh-lzu",
        "outputId": "d3572c5a-6a1c-4706-96ff-12492f2d043d"
      },
      "id": "ga1-p0bh-lzu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-Y0cAZOKMsTzbPy2B4QX8lPMU', created_at=1699431936, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-o0cVjSNF0kV27hbDuF1drh7M', result_files=[], status='queued', trained_tokens=None, training_file='file-VLN2wKKZ3ewndFbOgbZ6iWSv', validation_file=None)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()  # Make sure to initialize with your API key\n",
        "\n",
        "# Prepare the system message\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are an assistant expert in fish farming, providing detailed and accurate information on various aspects of fish cultivation, including breeding, feeding, and pond management.\"},\n",
        "]\n",
        "\n",
        "# List of test questions\n",
        "test_questions = [\n",
        "    \"What is the ideal water temperature for farming tilapia? Explain to me in detail.\"\n",
        "]\n",
        "\n",
        "# Add each test question to the messages\n",
        "for question in test_questions:\n",
        "    messages.append({\"role\": \"user\", \"content\": question})\n",
        "\n",
        "# Make the API call\n",
        "response = client.chat.completions.create(\n",
        "    model=\"ft:gpt-3.5-turbo-0613:personal::8Iay5z35\",  # Replace with your actual model\n",
        "    messages=messages\n",
        ")\n",
        "\n",
        "# Print the responses\n",
        "print(response.choices[0].message)"
      ],
      "metadata": {
        "id": "FODKAcr5CzJg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34b99a8e-db61-45eb-fbb8-435071483a2f"
      },
      "id": "FODKAcr5CzJg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='The ideal water temperature for farming tilapia is between 25°C and 30°C. Tilapia are tropical fish and require warm water for proper growth. Shall I explain why this temperature range is important?', role='assistant', function_call=None, tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gzY8rK-9JnEE"
      },
      "id": "gzY8rK-9JnEE",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}